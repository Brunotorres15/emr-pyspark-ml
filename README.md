# Deploy de uma Stack de Treinamento Distribuido de Machine Learning com PySpark e Amazon EMR e o impacto da Automa√ß√£o de Infraestrutura no Desenvolvimento de Modelos de Machine Learning. üöÄ

OBS: Esse projeto √© uma extens√£o/variante do projeto anterior: https://github.com/Brunotorres15/emr-flink-aws
No projeto anterior, foi automatizada toda uma infraestrutura de processamento distribu√≠do, que uma vez provisionada, nos permite submeter scripts pra processamento no cluster EMR; Neste novo projeto, os scripts s√£o disponibilizados junto com a infraestrutura e todo o processamento, treinamento do modelo e obten√ß√£o dos resultados j√° s√£o feitos de forma automatizada.

___

### üìå IA na era da informa√ß√£o e a ideia do projeto
Os modelos de Machine Learning est√£o se tornando essenciais em diversos setores do mercado, transformando a maneira como as empresas tomam decis√µes, otimizam opera√ß√µes e interagem com os clientes. De previs√µes de demanda e detec√ß√£o de fraudes a recomenda√ß√µes personalizadas e manuten√ß√£o preditiva, a aplica√ß√£o desses modelos est√° em plena expans√£o. No entanto, desenvolver e treinar esses modelos em escala requer uma infraestrutura robusta e eficiente, algo que muitas vezes pode ser um desafio significativo.

### üìå Como facilitar o desenvolvimento desses modelos?
A automa√ß√£o de uma infraestrutura para treinamento distribu√≠do de Machine Learning, como a exemplo desta solula√ß√£o utilizando o PySpark e Amazon EMR, oferece uma solu√ß√£o poderosa para enfrentar esses desafios. Atrav√©s de uma abordagem automatizada, √© poss√≠vel provisionar, configurar e gerenciar clusters de processamento de dados de forma eficiente e escal√°vel, atacando pontos importantes como a acelera√ß√£o do Desenvolvimento de Modelos, Escalabilidade Din√¢mica, Consist√™ncia e Reprodutibilidade.

### üìå Portanto, qual o impacto de uma solu√ß√£o como essa?
No contexto atual, onde os modelos de Machine Learning s√£o cada vez mais cruciais para o sucesso das empresas, ter uma solu√ß√£o automatizada para gerenciar a infraestrutura de treinamento desses modelos se torna um diferencial competitivo. A automa√ß√£o com PySpark e Amazon EMR n√£o s√≥ simplifica a complexidade operacional, mas tamb√©m potencializa o desenvolvimento de solu√ß√µes de Machine Learning mais r√°pidas, eficientes e econ√¥micas.

Implementar essa abordagem permite que as organiza√ß√µes mantenham a agilidade necess√°ria para responder √†s demandas do mercado, ao mesmo tempo em que promovem uma cultura de inova√ß√£o cont√≠nua. Em √∫ltima an√°lise, isso se traduz em uma capacidade aprimorada de transformar dados em a√ß√µes estrat√©gicas, impulsionando o crescimento e a competitividade.
___

## Porque eu escolhi utilizar essas ferramentas? (Pyspark, Amazon EMR e o Terraform?)
**PySpark**: Facilita o processamento distribu√≠do de grandes volumes de dados com uma interface simples em Python, integrando-se bem com o ecossistema Hadoop e oferecendo ferramentas robustas de Machine Learning.

**Amazon EMR**: Proporciona uma plataforma gerenciada e escal√°vel para executar frameworks de big data como Spark, reduzindo o esfor√ßo de configura√ß√£o e gerenciamento, e permitindo a escalabilidade autom√°tica e integra√ß√£o com outros servi√ßos AWS.

**Terraform**: Automatiza a provis√£o e gerenciamento da infraestrutura, garantindo consist√™ncia e reprodutibilidade, al√©m de permitir a implementa√ß√£o de infraestrutura como c√≥digo (IaC), o que facilita a manuten√ß√£o e atualiza√ß√£o de recursos na nuvem. 

## Estrutura do Projeto

```
üì¶ IaC
‚îú‚îÄ¬†dados
‚îú‚îÄ¬†modules
‚îú‚îÄ¬†pipelines
‚îú‚îÄ¬†scripts
‚îú‚îÄ¬†config.tf
‚îú‚îÄ¬†main.tf
‚îú‚îÄ¬†terraform.tfvars
‚îî‚îÄ¬†variables.tf
Dockerfile
```

O projeto est√° organizado em diferentes m√≥dulos do Terraform e scripts Python que s√£o executados no cluster EMR. A estrutura principal inclui os seguintes arquivos e pastas:

```main.tf: Arquivo principal do Terraform que chama os m√≥dulos necess√°rios.```

```modules/: Pasta contendo os m√≥dulos de Terraform para cria√ß√£o e configura√ß√£o dos recursos (EMR, network, iam, S3).```

```pipelines/: Pasta contendo os scripts Python que ser√£o executados no cluster EMR.```

```Scripts/: Pasta contendo o script em bash para instala√ß√£o das bibliotecas necess√°rias no cluster.```

```dados/: Pasta contentendo a fonte de dados que ser√° utilizada pra treinar o modelo.```

```config.tf/: Este arquivo cont√©m a configura√ß√£o inicial e o backend para o Terraform. Ele define onde o estado do Terraform ser√° armazenado, permitindo a colabora√ß√£o entre equipes e persist√™ncia do estado.```

```terraform.tfvars/: Este arquivo cont√©m os valores das vari√°veis definidas no variables.tf. Ele √© usado para fornecer valores espec√≠ficos de configura√ß√£o, como nomes de bucket, regi√µes, IDs de sub-redes, etc.```

```variable.tf/: Este arquivo define todas as vari√°veis utilizadas no main.tf e outros arquivos de configura√ß√£o. Cada vari√°vel pode ter um tipo, uma descri√ß√£o e um valor padr√£o.```

___

## Como replicar o projeto?

#### Clone o Reposit√≥rio
```
git clone https://github.com/Brunotorres15/emr-pyspark-ml.git
```

### Execute o comando abaixo para criar a imagem Docker

```
docker build -t emr-pyspark-ml-image:v1 .
```

### Execute o comando abaixo para criar o container Docker

```
docker run -dit --name emr-pyspark-ml-container -v ./IaC:/iac emr-pyspark-ml-image:v1 /bin/bash
```
NOTA: No Windows voc√™ deve substituir ./IaC pelo caminho completo da pasta

___
- *Cria√ß√£o do Bucket para armazenar o estado do terraform remotamente:*

 √â necess√°rio criar um Bucket S3 pra armazenazar o estado remoto do terraform, dessa forma, mesmo que localmente voc√™ perca seus arquivos, tendo o estado armazenado de forma remota, tanto voc√™, como seus colegas de equipe poder√£o destruir de forma automatizada tudo que foi provisionado com script do terraform que gerou aqueleq arquivo de estado.

 Uma vez que o bucket foi criado, basta colocar o nome dele em:
    ```
    bucket = nome-do-bucket
    ``` 
    no arquivo **config.tf**, dessa forma o terraform ir√° guardar o arquivo de estado no bucket informado.

- *Definir o nome dos buckets de armazenamento e de logs:*

No arquivo **terraform.tfvars**, nas op√ß√µes: 
```
name_bucket  = nome-do-bucket
```

```
log_uri_bucket = nome-do-bucket
```

voc√™ deve definir o nome desses buckets que ser√£o provisionados pelo terraform.




## Provisionando a Infraestrutura de processamento 



### Configure as suas credenciais de acesso √† AWS via cli
```
aws configure
```

### Inicialize o Terraform
```
terraform init
```
### üöÄ Provisionando toda a infraestrutura com dois comandos!

#### Cria o Plano de Execu√ß√£o do terraform e salva em disco

```
terraform plan -var-file terraform.tfvars -out terraform.tfplan
```
Obs: 
- *-var-file √© pra indicar qual arquivo de configura√ß√£o estamos utilizando pra buscar aos valores das vari√°veis que setamos.* 
- -out √© o arquivo de sa√≠da que vai guardar nosso plano de execu√ß√£o.

### Executa o apply do plano de execu√ß√£o, informando nomavente o arquivo onde est√£o as vari√°veis (com auto-approve)

```
terraform apply -auto-approve -var-file config.tfvars
```

### Opcional: Executa o apply com o arquivo de vari√°veis (sem auto-approve)
```
terraform apply -var-file config.tfvars
```

# Infraestrutura Provisionada!

Log do terraform provisionando os recursos.

![alt text](./images/terraform-provisioning.png)
***Visualizando o provisionamento da infraestrutura pelo docker-desktop***


Uma vez que o provisionamento aconteceu, voc√™ pode verificar que os clusters, buckets e execu√ß√£o dos scripts j√° ocorreram de forma automatizada, tudo conforme configuramos.


![alt text](./images/instancias-provisionadas.png)
***Master e Workers provisionados***

![alt text](./images/upload-automatizado.png)
***Buckets criados e upload dos arquivos realizados***

![alt text](./images/cluster-initializing.png)
***Cluster EMR sendo provisionado***

![alt text](./images/completed-steps.png)
***Steps sendo executado de forma automatizada***



# ‚úÖ Conclus√£o

*Com o uso do Terraform, automatizamos a cria√ß√£o e configura√ß√£o de clusters EMR, garantindo que todo o processo, desde a provis√£o da infraestrutura at√© o treinamento do modelo e obten√ß√£o dos resultados, fosse realizado de forma automatizada e eficiente.*

**üìå Resultados Alcan√ßados**

**Automa√ß√£o Completa**: Implementamos uma infraestrutura que permite a execu√ß√£o automatizada de scripts de treinamento de modelos de Machine Learning, eliminando a necessidade de interven√ß√µes manuais.

**Escalabilidade e Efici√™ncia**: Utilizando Amazon EMR, conseguimos escalar a infraestrutura conforme necess√°rio, otimizando o uso de recursos e reduzindo custos.

**Consist√™ncia e Reprodutibilidade**: Com Terraform, garantimos que a infraestrutura seja provisionada de forma consistente e reprodut√≠vel, facilitando a manuten√ß√£o e atualiza√ß√£o dos recursos.*

**Impacto**:
Ao simplificar a complexidade operacional e potencializar o desenvolvimento de solu√ß√µes de Machine Learning, essa abordagem automatizada n√£o s√≥ melhora a efici√™ncia e a economia, mas tamb√©m proporciona uma vantagem competitiva significativa. Em √∫ltima an√°lise, essa solu√ß√£o permite que as organiza√ß√µes transformem dados em a√ß√µes estrat√©gicas, impulsionando o crescimento e a competitividade no mercado.

Com essa infraestrutura, estamos bem posicionados para enfrentar os desafios futuros e continuar desenvolvendo solu√ß√µes de Machine Learning inovadoras e impactantes.